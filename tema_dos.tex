\section{Variables Aleatòries}
\subsection{Definició de variable aleatòria. Llei d'una v.a.}
Sigui $(\Omega, \mathcal{A}, \beta)$  un espai de probabilitat. Volem estudiar funcions de $\Omega$ amb imatge en $\real$.

\begin{defi}
  Una \textbf{variable aleatòria} és una funció $X\colon \Omega \to \real$ tal que per tot borelià B 
  $\in \mathcal{B}$, $\inv{X}(B) \in \mathcal{A}$. \\
  
  Per tant, una variable aleatòria és una funció mesurable entre els espais de mesura $(\Omega, \mathcal{A}, p)$ i $(\real, \mathcal{B}, \lambda)$.
\end{defi}

\begin{example}
  (1) Les funcions constants són variables aleatòries: \\
    \[
    \begin{aligned}
      X \colon \Omega &\to \real \\
      \omega &\mapsto c
    \end{aligned}
    \qquad \text{Si prenem } B \in \mathcal{B} \text{, } \inv{X}(B) =
    \begin{cases}
			\emptyset \quad \text{si c} \notin B\\
			\Omega \quad \text{si c} \in B
    \end{cases}
    \]
  \\
  
  (2) \textbf{Variables aleatòries indicadores}: 
    \[
    \hspace{-3.5cm}\text{Sigui A}  \in \mathcal{A}\text{, definim }\mathbbm{1}_{A}\colon \Omega \to \real \text{ on } \mathbbm{1}_{A}(\omega) = 
    \begin{cases}
			0 \quad \text{si } \omega \notin A\\
			1 \quad \text{si } \omega \in A
    \end{cases}\\
    \]
    \[
    \hspace{-3.5cm}\text{Aleshores, } B \in \mathcal{B}, \inv{\mathbbm{1}_{A}}(B) = 
    \begin{cases}
			\emptyset \quad \text{si } \setb{0, 1} \nsubseteq B\\
			A \quad \text{si } 1 \in B, \quad 0\notin B\\
			\overline{A} \quad \text{si } 1 \notin B, \quad 0 \in B\\
			\Omega \quad \text{si } \setb{0, 1} \nsubseteq B
    \end{cases}\\
    \]
    \\
    
    (3) Si X i Y són v.a., aleshores $X + Y$, $X\cdot Y$, $\abs{X}$, etc. són v.a. \\
    \- \hspace{0.5cm}En general, si $g\colon \real^{2} \to \real$ és una funció mesurable, aleshores g(X,Y) és una v.a.\\
\end{example}

Estem dient que $\forall B \in \mathcal{B}$, $\setb{\omega \in \Omega \colon X(\omega) \in B}$ és un succés i, per tant, podem calcular $P(\setb{\omega \in \Omega \colon X(\omega) \in B}) \equiv P(X \in B)$.\\

\begin{example}
  $P(X\leq 1) = P(\setb{\omega \in \Omega \colon X(\omega) \in (-\infty, 1)})$\\
\end{example}

Les v.a. permeten traslladar l'estructura d'espai de probabilitat de $(\Omega, \mathcal{A}, p)$ en $(\real, \mathcal{B})$, donant lloc a mesures que no provenen de la mesura de Lebesgue.\\

\newpage

\begin{defi}
  Siguin $(\Omega, \mathcal{A}, p)$ un espai de probabilitat i X una v.a. \\
  La \textbf{mesura de probabilitat induïda} per X és una mesura de probabilitat sobre $(\real, \mathcal{B})$ definida per
  \[
    \begin{aligned}
      p_{X} \colon \mathcal{B} &\to \real \\
      B &\mapsto p_{X} = P(\setb{\omega \in \Omega \colon X(\omega) \in B})
    \end{aligned}
  \]
  \\
\end{defi}

\begin{obs}
  $(\real, \mathcal{B},p_{X})$ és un espai de probabilitat.
\end{obs}

De teoria de la mesura, és equivalent veure que [$\forall B \in \mathcal{B}, \quad \inv{X}(B) \textit{ és de } \mathcal{A}$] a veure que [\textit{l'antiimatge de qualsevol interval} $\in \mathcal{A}$].\\\\
Per tant, per saber si una funció és una v.a. només cal veure si l'antiimatge dels intervals són de $\mathcal{A}$.\\

La següent definició dóna una funció en $\real$ que codifica molta informació de X:

\begin{defiImp}[(Fdp)]
  Donada X v.a., la \textbf{funció de distribució de probabilitat} de X és:
  \[
    \begin{aligned}
      F_{X} \colon \real &\to [0,1] \\
      x &\mapsto P(X \leq x)
    \end{aligned} 
  \]
\end{defiImp}

\begin{properties}
  (i) Si $x_{1} \leq x_{2} \implies F_{X}(x_{1}) \leq F_{X}(x_{2})$\\
  \[
  \hspace{-9.4cm}\text{(ii) }\lim_{x\to -\infty} F_{X}(x) = 0 \text{ ,  } \lim_{x\to+\infty} F_{X}(x) = 1
  \]
  (iii) $F_{X}(x)$ és contínua per la dreta: $\forall x, \lim_{h\to0^{+}}F_{X}(x+h) = F_{X}(x)$
\end{properties}

\begin{obs}
  \begin{itemize}
      \item []
      \item $P(X > x) = 1 - P(X\leq x) = 1 - F_{X}(x)$
      \item $P(x_{1} < X \leq x_{2}) = P(X \leq x_{2}) - P(X \leq x_{1}) = F_{X}(x_{2}) - F_{X}(x_{1})$
  \end{itemize}
\end{obs}

\begin{obs}
  Les propietats (i), (ii), (iii) de $F_{X}(x)$ són de fet suficients.\\
  Si una funció $F(x)$ satisfà (i), (ii), (iii), aleshores és funció de probabilitat d'una variable aleatòria.
\end{obs}
\newpage
\subsection{Moments d'una v.a.  Desigualtats de Markov i Chebyshev}

Siguin $(\Omega, \mathcal{A}, p)$ uns espai de probabilitat i X una v.a.\\
\begin{defi}
  L'\textbf{esperança} de X és: 
  \[
  \E[X] = \int_{\Omega}X dp = \int_{\real} x \, dp_{X}
  \]
  \\
  Més en general, si $f\colon \real \to \real$ és una funció mesurable, 
  \[
    \E[f(x)] = \int_{\Omega}f(x) dp = \int_{\real} f(x) \, dp_{X}
  \]
\end{defi}

\begin{obs}
  De teoria de la mesura, cal recordar que una funció $g$ és integrable sii $\abs{g}$ ho és
  (En general, $\E[f(x)]$ està definida sii $\E[\abs{f(x)}]<+\infty$). \\
\end{obs}

Si particularitzem $f$:

\begin{defi}
  $f(x) = X^{r} \implies \E[X^{r}]$ és el \textbf{moment r-èssim}.
\end{defi}

\begin{defi}
  Si $\E[X] = p < +\infty$, $\E[(X-p)^{r}]$ és el \textbf{moment normalitzat r-èssim}.\\\\
  En particular, si r = 2, $\E[(X-p)^{2}] = \mathbbm{V}ar[X]$ és la \textbf{variància} de $X$.
\end{defi}

\begin{defi}
  Si $f(x) = x(x-1)\ldots(x-r+1) \implies \E[f(x)] = \E[(X)_r]$ és el \textbf{moment factorial r-èssim}.
\end{defi}

\begin{prop}[(Propietats de l'esperança i la variància)]
  \begin{itemize}
      \item []
      \item Si $c$ és la v.a. constant, $\E[c] = c$ i $\mathbbm{V}ar[c] = 0$
      \item \underline{Linealitat}: si $a, b \in \real$ i $X, Y$ v.a., $\E[aX + bY] = a\E[X] + b\E[Y]$
      \item $A \in \mathcal{A}, X = \mathbbm{1}_{A}$, $\E[\mathbbm{1}_{A}] = P(A)$
      \item $\abs{\E[X]} \leq \E[\abs{X}]$
      \item $\mathbbm{V}ar[c\cdot X] = c^{2}\cdot \mathbbm{V}ar[X]$
      \item $\mathbbm{V}ar[c+X] = \mathbbm{V}ar[X]$
      \item $\mathbbm{V}ar[X] = \E[X^{2}] - (\E[X])^{2}$
  \end{itemize}
\end{prop}

\newpage

\begin{obs}
  Si $\E[\abs{X}^{p}] < +\infty$, aleshores podem utilitzar tots els resultats de teoria dels espais $L_{p}$. Així doncs tenim les següents conseqüències:
  
  \begin{itemize}
      \item \underline{Hölder}: $p, q > 0$, $\frac{1}{p} + \frac{1}{q} = 1, \, \E[\abs{X}^{p}] < +\infty, \E[\abs{Y}^{q}] < +\infty \\ \- \hspace{1.25cm}\implies \E[\abs{XY}] \leq \E[\abs{X}^{p}]^{\frac{1}{p}}\cdot \E[\abs{Y}^{q}]^{\frac{1}{q}} \quad (\E[\abs{XY}]^{pq} \leq \E[\abs{X}^{p}]^{q}\cdot \E[\abs{Y}^{q}]^{p})$
      
      \item \underline{Cauchy-Schwartz}: si $\E[X^{2}], \E[Y^2] < +\infty$, aleshores $\E[XY]^{2} \leq \E[X^{2}]\cdot \E[Y^{2}]$
      \item \underline{Minkowski}: si $\E[\abs{X}^{p}], \E[\abs{Y}^{p}] < +\infty \implies \E[\abs{X+Y}^{p}]^{\frac{1}{p}} \leq \E[\abs{X}^{p}]^{\frac{1}{p}} + \E[\abs{Y}^{p}]^{\frac{1}{p}}$
  \end{itemize}
\end{obs}

\begin{thm}[(Desigualtat de Markov)]
  Sigui $X$ un v.a. que pren valors positius i $a > 0$. Aleshores: \\
  \[
    P(X \geq a) \leq \frac{\E[X]}{a}
  \]
\end{thm}

El següent resultat dóna estimacions quantitatives de quant es dispersa una v.a. en relació a la seva esperança:

\begin{thm}[(Desigualtat de Chebyshev)]
  Sigui X una v.a. en $(\Omega, \mathcal{A}, p)$ amb $\E[X], \V ar[X] < +\infty$. Aleshores, $\forall k > 0$
  \[
    P(\abs{X-\E[X]}\geq k\cdot \V ar[X]^{\frac{1}{2}}) \leq \frac{1}{k^{2}}
  \]
  També es pot escriure:
  \[
    P(\abs{X-\E[X]}\geq k) \leq \frac{\V ar[X]}{k^{2}}
  \]
\end{thm}

\newpage
\subsection{Vectors de variables aleatòries. Independència de v.a.}
